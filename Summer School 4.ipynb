{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08c9d738",
   "metadata": {},
   "source": [
    "# Knowledge Intensive NLP Summer School\n",
    "\n",
    "## Notebook 4\n",
    "\n",
    "The goals of this notebook are:\n",
    "\n",
    "* Evaluate the knowledge captured within two langauge models: Flan-T5 and OpenAI GPT-3.5\n",
    "* Explore how using different prompts affects the answers given by the models\n",
    "* Explore where information is cut off\n",
    "\n",
    "The API key for OpenAI will be provided seprarately. To avoid unncessary costs, please do not call the OpenAPI from within a loop or iterator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebc7edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-0.27.8-py3-none-any.whl (73 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from requests>=2.20->openai) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from requests>=2.20->openai) (2023.5.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./miniconda3/envs/summerschool/lib/python3.8/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Installing collected packages: openai\n",
      "Successfully installed openai-0.27.8\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac14acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASTE OPENAI KEY HERE BEFORE IMPORTING OPENAI. ELSE, RESTART WORKSPACE\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-sS0BkzsPBjkDJiczNvlyT3Bl......\" # Find the rest of the key on my website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc6ed24",
   "metadata": {},
   "source": [
    "# Prelude\n",
    "\n",
    "We will use two LLMs. OpenAI and FLAN-T5, an instruction tuned version of the T5 language model. This section shows simple ways to call the models to generate an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af2e8120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def call_openai(message):    \n",
    "    response = openai.ChatCompletion.create(\n",
    "\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": message}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cfad5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n",
      "I'm sorry, but as an AI language model, I don't have real-time data. Weather conditions change frequently, so I recommend checking a reliable weather website or using a weather app for up-to-date information on the weather in Italy today.\n"
     ]
    }
   ],
   "source": [
    "message = call_openai(\"What is the capital of France?\")\n",
    "print(message)\n",
    "\n",
    "message = call_openai(\"What is the weather in Italy today?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf31570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-base\")\n",
    "\n",
    "def call_flanT5(message):\n",
    "    input_text = message\n",
    "    input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "    outputs = model.generate(input_ids)\n",
    "    return tokenizer.decode(outputs[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4c6c8d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "london\n",
      "Paris\n"
     ]
    }
   ],
   "source": [
    "message = call_flanT5(\"What is the capital of France?\")\n",
    "print(message)\n",
    "\n",
    "message = call_flanT5(\"Answer the question using information from Wikipedia: What is the capital of France?\")\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32975bbb",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "## Understanding knowlege\n",
    "\n",
    "1) Think about a topic that most people are familiar with. Generate some questions to ask GPT-3.5 and T5 models without any additional context information. Do the models answer correctly?\n",
    "2) For the T5 model, experiment with variations of the question or chosing different prompts. Does this cause the answer accuracy to change?\n",
    "3) Pick a random/obscure Wikipedia page and generate a set of questions about a topic where the models don't answer correctly. \n",
    "4) Provide the model with the context as well as the question. Can you make prompts where the question is correctly answered?\n",
    "5) Experiment with sampling answers from the model and the effect of temperate setting (search for sampling temperature for HuggingFace and OpenAI). Does this affect the factuality of the model answers?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Summer School",
   "language": "python",
   "name": "summerschool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
